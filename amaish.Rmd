---
title: "Assignment 1 & 2"
subtitle: "Data cleaning & Model Building"
author: "Magnus BK, Carl-Magnus, Jan Kostkan, Anders Weile, Victor Møller"
date: "\today{}"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#libraries
library(pacman)
p_load(tidyverse, lme4, corrplot, RColorBrewer, lmerTest, effects, MuMIn, cowplot,ggthemes,magick) 

#loading data
data <- read.csv("language_dev_asd_clean_2.csv") #data from assignment 1 

#right format 
str(data) 

#conversion
data$SUBJ <- as.factor(data$SUBJ) 
data$VISIT <- as.factor(data$VISIT)

#well matched? 
participants <- data %>%
  filter(VISIT == 6)

summary(participants$Diagnosis) #29 ASD & 32 TD 

#creating subsets for age 
data_ASD <- data %>%
  filter(!is.na(Age) & VISIT == 1 & Diagnosis == "ASD") 

data_TD <- data %>%
  filter(!is.na(Age) & VISIT == 1 & Diagnosis == "TD") 

#z-score for ASD
data_ASD <- data_ASD %>% 
  mutate(ageZ = scale(Age))

data_TD <- data_TD %>%
  mutate(ageZ = scale(Age))

#summary ASD
summary(data_ASD$ageZ) #bigger z-scores, some very old and young 
which(data_ASD$ageZ > 2) # 
which(data_ASD$ageZ < -2) #8

#summary TD
summary(data_TD$ageZ) #somewhat smaller z-scores 
which(data_TD$ageZ > 2) #2, 29 
which(data_TD$ageZ < -2) #none

#comparing means 
difference <- mean(data_TD$Age) - mean(data_ASD$Age)
difference #huge difference of 12.6 (months older in general)

#comparing means with Z
z_diff <- mean(data_TD$ageZ) - mean(data_ASD$ageZ)
z_diff #very very small. 

#histograms
hist(data_ASD$ageZ) #we have one huge outlier (younger)
hist(data_TD$ageZ) #A couple of outliers (older)

hist(data_ASD$Age) 
hist(data_TD$Age) #don't get quite as old - matching production. 
summary(data_ASD$Age) #18.77 - 42

#Gender
summary(data_ASD$Gender) #Female = 146, Male = 26
summary(data_TD$Gender) #Female = 155, Male = 35

#Ethnicity
summary(data_ASD$Ethnicity) #ASD mainly white & some scattered. 
summary(data_TD$Ethnicity) #TD only white & asian 

#random intercepts
data$Kid = factor(data$SUBJ) #from lecture 

#plotting w. colors
ggplot(data, aes(as.numeric(VISIT), CHI_MLU, color = Diagnosis)) +
  geom_point() + 
  geom_smooth(method = "lm")

#boxplot 
ggplot(data, aes(Diagnosis, CHI_MLU))+
  geom_boxplot() #outliers in ASD. 

#beeswarm plot
p_load(beeswarm)

boxplot(CHI_MLU ~ Diagnosis, data = data, 
  outline = FALSE,    
  main = 'boxplot + beeswarm')
beeswarm(CHI_MLU ~ Diagnosis, data = data, 
  col = 4, pch = 16, add = TRUE)

#violin plot 
ggplot(data, aes(Diagnosis, CHI_MLU)) +
  geom_violin(aes(fill = CHI_MLU)) +
  geom_boxplot(width = 0.2)

#linear mixed effects model 
data$VISIT <- as.integer(data$VISIT) #crucial to run the model 

model_data <- data %>%
  filter(!is.na(CHI_MLU) & !is.na(VISIT) & !is.na(Diagnosis))

#different potential models 
library(MuMIn)

mixed_model <- lmer(CHI_MLU ~ VISIT * Diagnosis + (1+VISIT|SUBJ), data = model_data, REML=FALSE)
summary(mixed_model) #VISIT very significant, DiagnosisTD not significant. 
r.squaredGLMM(mixed_model) #R2m = fixed, R2c = fixed + random. 

#Other models 
model_simple <- lmer(CHI_MLU ~ VISIT + (1+VISIT|SUBJ), model_data, REML=FALSE)
model_diagnosis <- lmer(CHI_MLU ~ Diagnosis + (1+VISIT|SUBJ), data = model_data, REML=FALSE)
model_noint <- lmer(CHI_MLU ~ VISIT + Diagnosis + (1+VISIT|SUBJ), data = model_data, REML=FALSE)

#pairwise anova tests 
anova(model_simple, mixed_model) #mixed model not sign. better
anova(model_diagnosis, mixed_model) #mixed model sign. better
anova(model_noint, mixed_model) #model_simple sign. better

#r-squared for the two best models (model_simple, mixed_model)
r.squaredGLMM(mixed_model) #mixed model has highest marginal r-squared. 
r.squaredGLMM(model_noint) 

#visualizing quadratic 
plot2 <- ggplot(data, aes(as.numeric(VISIT), CHI_MLU, color = Diagnosis)) +
  geom_point() + 
  stat_smooth(method = "lm", formula = y ~ poly(x, 2)) +
  labs(x = "visit", y = "", legend = "", title = "quadratic")

#visualizing Cubic
plot3 <- ggplot(data, aes(as.numeric(VISIT), CHI_MLU, color = Diagnosis)) +
  geom_point() + 
  stat_smooth(method = "lm", formula = y ~ poly(x, 3)) +
  labs(x = "visit", y = "", title = "cubic")

#visualizing linear
plot1 <- ggplot(data, aes(as.numeric(VISIT), CHI_MLU, color = Diagnosis)) +
  geom_point() + 
  stat_smooth(method = "lm") +
  labs(x = "visit", y = "child mean length of utterance (MLU)", title = "linear")

#spaghetti plot
ggplot(data, aes(VISIT, CHI_MLU, slope = SUBJ, color = Diagnosis)) +
  geom_smooth() #disgusting. 

#different models 
m_linear <- lmer(CHI_MLU ~ VISIT*Diagnosis + (1+VISIT|SUBJ), data = model_data, REML=FALSE)

m_quadratic <- lmer(CHI_MLU ~ (VISIT + I(VISIT^2))*Diagnosis + (1+VISIT + I(VISIT^2)|SUBJ), data = model_data, REML=FALSE)

m_cubic <- lmer(CHI_MLU ~ (VISIT+ I(VISIT^2)+ I(VISIT^3))*Diagnosis + (1+VISIT + I(VISIT^2) + I(VISIT^3)|SUBJ), data = model_data, REML=FALSE)

#evaluating them 
library(lmerTest)
summary(m_cubic) #cubic seems to perform poorly (i.e., have non-significant effects)
summary(m_quadratic) #quadratic seems to perform well (i.e., have significant effects)
summary(m_linear)

#comparing them 
anova(m_linear, m_quadratic) #quadratic best
anova(m_quadratic, m_cubic) #qubic best
anova(m_linear, m_cubic) #qubic best 

#comparison of r-squared 
r.squaredGLMM(m_quadratic) # R2m = .23
r.squaredGLMM(m_cubic) # R2m = .22
r.squaredGLMM(m_linear) # R2m = .22

#effects package plotting (quadratic)
library(effects)
ef <- effect("VISIT:Diagnosis", m_quadratic, xlevels = 6)
summary(ef) #visit 3 

eff_plot <- as.data.frame(ef)
eff_plot

ggplot(eff_plot, aes(VISIT, fit, color=Diagnosis)) + geom_point() + geom_errorbar(aes(ymin=fit-se, ymax=fit+se), width=0.4) + theme_bw(base_size=12)  

#this only gives us 5 levels
plot(predictorEffects(m_quadratic))

#visualizing lineaer
ggplot(data, aes(as.numeric(VISIT), MOT_MLU, color = Diagnosis)) +
  geom_point() + 
  stat_smooth(method = "lm") +
  labs(x = "visit", y = "mother mean length of utterance (MLU)")

#visualizing quadratic 
ggplot(data, aes(as.numeric(VISIT), MOT_MLU, color = Diagnosis)) +
  geom_point() + 
  stat_smooth(method = "lm", formula = y ~ poly(x, 2)) +
  labs(x = "visit", y = "mother mean length of utterance (MLU)")

#visualizing Cubic
ggplot(data, aes(as.numeric(VISIT), MOT_MLU, color = Diagnosis)) +
  geom_point() + 
  stat_smooth(method = "lm", formula = y ~ poly(x, 3))

#different models 
mot_linear <- lmer(MOT_MLU ~ VISIT*Diagnosis + (1+VISIT|SUBJ), data = model_data, REML=FALSE)

mot_quadratic <- lmer(MOT_MLU ~ (VISIT + I(VISIT^2))*Diagnosis + (1+VISIT + I(VISIT^2)|SUBJ), data = model_data, REML=FALSE)

mot_cubic <- lmer(MOT_MLU ~ (VISIT+ I(VISIT^2)+ I(VISIT^3))*Diagnosis + (1+VISIT + I(VISIT^2) + I(VISIT^3)|SUBJ), data = model_data, REML=FALSE)

#summaries
summary(mot_cubic) #needs interpretation
summary(mot_quadratic) #needs interpretation 
summary(mot_linear)

#comparison
anova(mot_linear, mot_quadratic, mot_cubic)

#comparison pairwie 
anova(mot_quadratic, mot_cubic) #cubic not significantly better
anova(mot_linear, mot_quadratic) #quadratic significantly better 

#r-squared
r.squaredGLMM(mot_quadratic) # R2m = .24
r.squaredGLMM(mot_cubic) # R2m = .23
r.squaredGLMM(mot_linear) # R2m = .23 

#initial correlation
cor_data = select(model_data, VISIT, Age, ADOS_1, nonVerbalIQ_1, verbalIQ_1, MOT_MLU, types_MOT, tokens_MOT, types_CHI, tokens_CHI, CHI_MLU) %>%
  filter(!is.na(Age))

corr = round(cor(cor_data,method = "spearman"),2)

#stepwise w. lmer for quadratic  
big_model <- lmer(CHI_MLU ~ (VISIT + I(VISIT^2))*Diagnosis + (1+VISIT + I(VISIT^2)|SUBJ) + Gender + Ethnicity + ADOS_1 + nonVerbalIQ_1 + verbalIQ_1, data = model_data, REML=FALSE)
summary(big_model)

big_model <- lmer(CHI_MLU ~ (VISIT + I(VISIT^2))*Diagnosis + (1+VISIT + I(VISIT^2)|SUBJ) + verbalIQ_1, data = model_data, REML=FALSE)

(step_res <- step(big_model))
final <- get_model(step_res)
anova(final) 
summary(final) #works, good t-values 

#compared to the quadratic model earlier 
anova(m_quadratic, big_model) 
anova(big_model) 

#r-squared
r.squaredGLMM(big_model) #R2m .6
```

\tableofcontents

# Exercise 1) Characterizing the participants:

## Evaluating how the groups match:

* Number of participants: The two groups are relatively well matched. At the beginning of the experiment the group containing the typically-developing children is slightly larger: (ASD: 29, TD: 32). However, the group sizes equal out by visit 6 (28 participants in both groups).

* Mean MLU at first visit: The groups are well matched in MLU at the first visit.

* Age: The mean age of the two groups are not well matched. The participants in the ASD group are on average 12.63 months older than those in the TD group. Additionally, the age distribution of the ASD contains more variance than the TD group, perhaps because of more within-group variability in language development. This could be a confounding factor, since the older children in the ASD group might have a slower growth curve than the younger ones. However, the main aim has been to match the children by their mean MLU, which is what has been primarily controlled for by the experimenters.

* Ethnicity: Pretty well-matched between ASD and TD. However, both samples consist mainly of white people. Number of participants of other ethnic groups did not exceed 2 in either group. Thus, the variable does not seem to be of much value.

* Gender: The groups are well matched (ASD: M: 25 & F: 4) (TD: M: 26 & F: 6) → Males are prevalent in both groups, so one should be careful with extrapolation from findings to the wider population (especially women).


## Hypothesis 1: 
Children with ASD display a language impairment

Before creating our statistical model, we plot the data. 
We used a combined **svliocatooth** plot to highlight the development between the groups as well as the variability for both groups. 
```{r cars, echo = FALSE, messages = FALSE}
#plotting w. colors
# SPLIT VIIOLIN FUNCITON
GeomSplitViolin <- ggproto("GeomSplitViolin", GeomViolin, 
                           draw_group = function(self, data, ..., draw_quantiles = NULL) {
                             data <- transform(data, xminv = x - violinwidth * (x - xmin), xmaxv = x + violinwidth * (xmax - x))
                             grp <- data[1, "group"]
                             newdata <- plyr::arrange(transform(data, x = if (grp %% 2 == 1) xminv else xmaxv), if (grp %% 2 == 1) y else -y)
                             newdata <- rbind(newdata[1, ], newdata, newdata[nrow(newdata), ], newdata[1, ])
                             newdata[c(1, nrow(newdata) - 1, nrow(newdata)), "x"] <- round(newdata[1, "x"])
                             
                             if (length(draw_quantiles) > 0 & !scales::zero_range(range(data$y))) {
                               stopifnot(all(draw_quantiles >= 0), all(draw_quantiles <=
                                                                         1))
                               quantiles <- ggplot2:::create_quantile_segment_frame(data, draw_quantiles)
                               aesthetics <- data[rep(1, nrow(quantiles)), setdiff(names(data), c("x", "y")), drop = FALSE]
                               aesthetics$alpha <- rep(1, nrow(quantiles))
                               both <- cbind(quantiles, aesthetics)
                               quantile_grob <- GeomPath$draw_panel(both, ...)
                               ggplot2:::ggname("geom_split_violin", grid::grobTree(GeomPolygon$draw_panel(newdata, ...), quantile_grob))
                             }
                             else {
                               ggplot2:::ggname("geom_split_violin", GeomPolygon$draw_panel(newdata, ...))
                             }
                           })

geom_split_violin <- function(mapping = NULL, data = NULL, stat = "ydensity", position = "identity", ..., 
                              draw_quantiles = NULL, trim = TRUE, scale = "area", na.rm = FALSE, 
                              show.legend = NA, inherit.aes = TRUE) {
  layer(data = data, mapping = mapping, stat = stat, geom = GeomSplitViolin, 
        position = position, show.legend = show.legend, inherit.aes = inherit.aes, 
        params = list(trim = trim, scale = scale, draw_quantiles = draw_quantiles, na.rm = na.rm, ...))
}


## THE PLOT
good <- ggplot(data, aes(as.numeric(VISIT), CHI_MLU)) +
  geom_split_violin(alpha = 0.6, 
                    bw = "nrd0",
                    width = 1.2,
                    scale = "count",
                    aes(fill = Diagnosis, 
                        group = interaction(Diagnosis, VISIT))) +
  geom_point(aes(color = Diagnosis), 
             alpha = 0.45, 
             position = position_jitterdodge()) +
  stat_smooth(aes(color = Diagnosis, fill = Diagnosis), 
              method = "lm", 
              formula = y ~ poly(x, 2),
              alpha = 0.6) +
  theme_bw() +
  scale_fill_tableau() +
  scale_color_tableau() +
  scale_x_continuous(breaks=seq(1,6,1)) +
  labs(title = "Development of Child's MLU",
       #subtitle = "", 
       x = "Visit number", 
       y = "Child's MLU")

good



```

The plot displays some trends in the data. Firstly, it shows that the two groups share an intercept because of the matching done by the experimenters. However, the TD group displays a steeper curve, showing that the TD children have a faster growth in their MLU. This indicates that there could be a significant interaction between diagnosis and visit. In addition, it appears like the growth decreases as a function of time, indicating that the development might follow a non-linear trend. Furthermore, the TD slope displays narrower confidence intervals, indicating smaller variance in this group compared to the ASD group. 

## simple mixed effects model 
In the mixed effects model, we chose to include 

```{r, echo = FALSE, messages = FALSE}
#mixed model 
summary(mixed_model) #VISIT very significant, DiagnosisTD not significant. 
r.squaredGLMM(mixed_model) #R2m = fixed, R2c = fixed + random. 
```

testing the model with interaction (mixed_model) against the one without (model_noint)

```{r, echo = FALSE, messages = FALSE}
#comparison of mixed model with the same without interaction 
anova(model_noint, mixed_model)

```

plotting models with varrying higher order blabla

```{r, echo=FALSE, messages = FALSE}
#growth curves plot
plot_grid(plot1, plot2, plot3, labels = "AUTO")

```

Seems like the data fits better with quadratic / cubic than linear

```{r, echo=FALSE, messages = FALSE}
#growth curves test 
anova(m_quadratic, m_cubic, m_linear)

```

quadratic chosen because lowest BIC and interpretability 

```{r, echo=FALSE, messages = FALSE}
#r-squared of the chosen model
r.squaredGLMM(m_cubic) 
```

other r-squared values at github. 

```{r, echo=FALSE, messages = FALSE}

```

[report results]

-------------------------------------------------------------------------------------------------

Hypothesis 2

```{r, echo=FALSE, messages = FALSE}
#comparison of models for mommy (beware of BIC)
anova(mot_linear, mot_quadratic, mot_cubic)
```

```{r, echo=FALSE, messages = FALSE}
#r-squared for best model - perhaps replace with linear. 
r.squaredGLMM(mot_quadratic)
```

[report results]

exercise 4
output of the best model (explain how we got here baby)

```{r, echo=FALSE, messages = FALSE}
anova(final) 
```

r-squared for the best model 

```{r, echo = FALSE, messages = FALSE}
r.squaredGLMM(final)
```

```{r, echo = FALSE, messages = FALSE}

```

